{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Densenet Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torchsummary in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (1.5.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torchvision in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (0.16.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torchvision) (1.26.3)\n",
            "Requirement already satisfied: requests in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.2 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torchvision) (2.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch==2.1.2->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch==2.1.2->torchvision) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch==2.1.2->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch==2.1.2->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch==2.1.2->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from torch==2.1.2->torchvision) (2023.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from requests->torchvision) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from matplotlib) (6.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\aless\\documents\\university\\vision\\project\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch\n",
        "%pip install torchsummary\n",
        "%pip install torchvision\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#import matplotlib.pyplot as plt\n",
        "#from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "#from torchsummary import summary\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lovin the GPU\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if torch.cuda.is_available:\n",
        "    print('lovin the GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants\n",
        "OUTPUT_DIM = 4  # Change this to your number of classes\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "N_EPOCHS = 15\n",
        "\n",
        "# Define transforms\n",
        "mean_imagenet = [0.485, 0.456, 0.406]\n",
        "std_imagenet = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform_imagenet = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_imagenet, std_imagenet)\n",
        "])\n",
        "\n",
        "test_transform_imagenet = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_imagenet, std_imagenet)\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset_imagenet = datasets.ImageFolder(root='Data/archive/grape_dataset/train', transform=train_transform_imagenet)\n",
        "test_dataset_imagenet = datasets.ImageFolder(root='Data/archive/grape_dataset/test', transform=test_transform_imagenet)\n",
        "\n",
        "# Create data loaders\n",
        "train_iterator_imagenet = DataLoader(train_dataset_imagenet, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "test_iterator_imagenet = DataLoader(test_dataset_imagenet, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "# Define the model\n",
        "class DenseNet121(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.dense_net = models.densenet121(pretrained=True)\n",
        "        num_features = self.dense_net.classifier.in_features\n",
        "        self.dense_net.classifier = nn.Identity()\n",
        "        self.fc = nn.Linear(num_features, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dense_net(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "dense_net121_extract = DenseNet121(OUTPUT_DIM).to(device)\n",
        "\n",
        "# Define the optimizer (added L2 regularization)\n",
        "optimizer = optim.Adam(dense_net121_extract.parameters(), weight_decay=0.01)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training function\n",
        "def model_training(N_EPOCHS, model, train_iterator, valid_iterator, optimizer, criterion, device, model_name='model.pt'):\n",
        "    best_valid_loss = float('inf')\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "        for inputs, labels in train_iterator:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_iterator:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                predictions = model(inputs)\n",
        "                loss = criterion(predictions, labels)\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch: {epoch+1}/{N_EPOCHS}.. Training Loss: {train_loss/len(train_iterator):.3f}.. Validation Loss: {valid_loss/len(valid_iterator):.3f}')\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), model_name)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model_training(N_EPOCHS, dense_net121_extract, train_iterator_imagenet, test_iterator_imagenet, optimizer, criterion, device, model_name='dense_net121.pt')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
